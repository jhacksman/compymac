{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f4c09a6",
   "metadata": {},
   "source": [
    "# Cognitive Analysis Dashboard\n",
    "\n",
    "V5 Metacognitive Architecture Analysis Tool\n",
    "\n",
    "This notebook provides visualization and analysis of cognitive events captured during agent execution.\n",
    "\n",
    "## Features\n",
    "- Thinking compliance rate by phase\n",
    "- Most common thinking scenarios triggered\n",
    "- Temptation encounter/resistance rates\n",
    "- Decision point timeline visualization\n",
    "- Reasoning coherence samples for manual review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa6d296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path for imports\n",
    "sys.path.insert(0, str(Path.cwd().parent / \"src\"))\n",
    "\n",
    "from compymac.trace_store import TraceStore, create_trace_store, CognitiveEvent\n",
    "from compymac.temptations import Temptation, TEMPTATION_CATALOG\n",
    "from compymac.swe_workflow import SWEPhase\n",
    "\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa603d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DB_PATH = None  # Use default path, or specify custom path\n",
    "TRACE_ID = None  # Set to specific trace_id or None to analyze all\n",
    "\n",
    "# Create trace store connection\n",
    "store = create_trace_store(db_path=DB_PATH)\n",
    "print(f\"Connected to trace store\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329caa8b",
   "metadata": {},
   "source": [
    "## 1. Load Cognitive Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae09d945",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cognitive_events(store: TraceStore, trace_id: str | None = None) -> list[CognitiveEvent]:\n",
    "    \"\"\"Load cognitive events from trace store.\"\"\"\n",
    "    if trace_id:\n",
    "        return store.get_cognitive_events(trace_id)\n",
    "    else:\n",
    "        print(\"Please specify a TRACE_ID to analyze\")\n",
    "        return []\n",
    "\n",
    "events = load_cognitive_events(store, TRACE_ID)\n",
    "print(f\"Loaded {len(events)} cognitive events\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3dbae1",
   "metadata": {},
   "source": [
    "## 2. Thinking Compliance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7004698b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_thinking_compliance(events: list[CognitiveEvent]) -> dict:\n",
    "    \"\"\"Analyze thinking compliance by phase and scenario.\"\"\"\n",
    "    thinking_events = [e for e in events if e.event_type == \"think\"]\n",
    "    \n",
    "    by_phase = {}\n",
    "    for event in thinking_events:\n",
    "        phase = event.phase or \"unknown\"\n",
    "        if phase not in by_phase:\n",
    "            by_phase[phase] = []\n",
    "        by_phase[phase].append(event)\n",
    "    \n",
    "    scenario_counts = Counter()\n",
    "    for event in thinking_events:\n",
    "        trigger = event.metadata.get(\"trigger\", \"unspecified\") if event.metadata else \"unspecified\"\n",
    "        scenario_counts[trigger] += 1\n",
    "    \n",
    "    required_scenarios = [\n",
    "        \"before_claiming_completion\",\n",
    "        \"before_advancing_to_fix\",\n",
    "        \"before_git_operations\",\n",
    "    ]\n",
    "    \n",
    "    scenario_compliance = {}\n",
    "    for scenario in required_scenarios:\n",
    "        satisfied = any(\n",
    "            scenario in (e.metadata.get(\"trigger\", \"\") or \"\")\n",
    "            for e in thinking_events\n",
    "            if e.metadata\n",
    "        )\n",
    "        scenario_compliance[scenario] = satisfied\n",
    "    \n",
    "    return {\n",
    "        \"total_thinking_events\": len(thinking_events),\n",
    "        \"by_phase\": {k: len(v) for k, v in by_phase.items()},\n",
    "        \"scenario_counts\": dict(scenario_counts),\n",
    "        \"required_scenario_compliance\": scenario_compliance,\n",
    "        \"compliance_rate\": sum(scenario_compliance.values()) / len(required_scenarios) if required_scenarios else 1.0,\n",
    "    }\n",
    "\n",
    "thinking_analysis = analyze_thinking_compliance(events)\n",
    "print(\"=== Thinking Compliance Analysis ===\")\n",
    "print(f\"Total thinking events: {thinking_analysis['total_thinking_events']}\")\n",
    "print(f\"By phase: {thinking_analysis['by_phase']}\")\n",
    "print(f\"Scenario triggers: {thinking_analysis['scenario_counts']}\")\n",
    "print(f\"Required scenario compliance: {thinking_analysis['required_scenario_compliance']}\")\n",
    "print(f\"Overall compliance rate: {thinking_analysis['compliance_rate']:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6804875",
   "metadata": {},
   "source": [
    "## 3. Temptation Awareness Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364961ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_temptations(events: list[CognitiveEvent]) -> dict:\n",
    "    \"\"\"Analyze temptation encounter and resistance rates.\"\"\"\n",
    "    temptation_events = [e for e in events if e.event_type == \"temptation_awareness\"]\n",
    "    \n",
    "    by_type = Counter()\n",
    "    recognized_count = 0\n",
    "    resisted_count = 0\n",
    "    \n",
    "    for event in temptation_events:\n",
    "        if event.metadata:\n",
    "            temptation_type = event.metadata.get(\"temptation\", \"unknown\")\n",
    "            by_type[temptation_type] += 1\n",
    "            if event.metadata.get(\"recognized\", False):\n",
    "                recognized_count += 1\n",
    "            if event.metadata.get(\"resisted\", False):\n",
    "                resisted_count += 1\n",
    "    \n",
    "    total = len(temptation_events)\n",
    "    return {\n",
    "        \"total_encountered\": total,\n",
    "        \"by_type\": dict(by_type),\n",
    "        \"recognized\": recognized_count,\n",
    "        \"resisted\": resisted_count,\n",
    "        \"recognition_rate\": recognized_count / total if total > 0 else 1.0,\n",
    "        \"resistance_rate\": resisted_count / total if total > 0 else 1.0,\n",
    "    }\n",
    "\n",
    "temptation_analysis = analyze_temptations(events)\n",
    "print(\"=== Temptation Awareness Analysis ===\")\n",
    "print(f\"Total encountered: {temptation_analysis['total_encountered']}\")\n",
    "print(f\"By type: {temptation_analysis['by_type']}\")\n",
    "print(f\"Recognition rate: {temptation_analysis['recognition_rate']:.1%}\")\n",
    "print(f\"Resistance rate: {temptation_analysis['resistance_rate']:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179c9915",
   "metadata": {},
   "source": [
    "## 4. Decision Point Timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda0b553",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_timeline(events: list[CognitiveEvent]) -> list[dict]:\n",
    "    \"\"\"Create a timeline of cognitive events.\"\"\"\n",
    "    timeline = []\n",
    "    for event in sorted(events, key=lambda e: e.timestamp):\n",
    "        timeline.append({\n",
    "            \"timestamp\": datetime.fromtimestamp(event.timestamp).strftime(\"%H:%M:%S\"),\n",
    "            \"type\": event.event_type,\n",
    "            \"phase\": event.phase or \"unknown\",\n",
    "            \"content_preview\": (event.content[:100] + \"...\") if event.content and len(event.content) > 100 else event.content,\n",
    "        })\n",
    "    return timeline\n",
    "\n",
    "timeline = create_timeline(events)\n",
    "print(\"=== Cognitive Event Timeline ===\")\n",
    "for entry in timeline[:20]:\n",
    "    print(f\"[{entry['timestamp']}] {entry['type']:20} | {entry['phase']:15} | {entry['content_preview'] or '(no content)'}\")\n",
    "if len(timeline) > 20:\n",
    "    print(f\"... and {len(timeline) - 20} more events\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48f833b",
   "metadata": {},
   "source": [
    "## 5. Reasoning Coherence Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9615af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reasoning_samples(events: list[CognitiveEvent], n: int = 5) -> list[dict]:\n",
    "    \"\"\"Get sample thinking events for manual coherence review.\"\"\"\n",
    "    thinking_events = [e for e in events if e.event_type == \"think\" and e.content]\n",
    "    \n",
    "    samples = []\n",
    "    if thinking_events:\n",
    "        samples.append(thinking_events[0])\n",
    "        if len(thinking_events) > 1:\n",
    "            samples.append(thinking_events[-1])\n",
    "        if len(thinking_events) > 2:\n",
    "            mid = len(thinking_events) // 2\n",
    "            samples.append(thinking_events[mid])\n",
    "        while len(samples) < min(n, len(thinking_events)):\n",
    "            idx = len(samples) * len(thinking_events) // n\n",
    "            if thinking_events[idx] not in samples:\n",
    "                samples.append(thinking_events[idx])\n",
    "            else:\n",
    "                break\n",
    "    \n",
    "    return [\n",
    "        {\n",
    "            \"timestamp\": datetime.fromtimestamp(e.timestamp).strftime(\"%H:%M:%S\"),\n",
    "            \"phase\": e.phase,\n",
    "            \"trigger\": e.metadata.get(\"trigger\", \"unspecified\") if e.metadata else \"unspecified\",\n",
    "            \"content\": e.content,\n",
    "        }\n",
    "        for e in samples\n",
    "    ]\n",
    "\n",
    "samples = get_reasoning_samples(events)\n",
    "print(\"=== Reasoning Coherence Samples ===\")\n",
    "for i, sample in enumerate(samples, 1):\n",
    "    print(f\"--- Sample {i} ---\")\n",
    "    print(f\"Time: {sample['timestamp']} | Phase: {sample['phase']} | Trigger: {sample['trigger']}\")\n",
    "    print(f\"Content: {sample['content']}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259270b1",
   "metadata": {},
   "source": [
    "## 6. Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec6f353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary_report(events: list[CognitiveEvent]) -> dict:\n",
    "    \"\"\"Generate a comprehensive summary report.\"\"\"\n",
    "    thinking = analyze_thinking_compliance(events)\n",
    "    temptations = analyze_temptations(events)\n",
    "    event_types = Counter(e.event_type for e in events)\n",
    "    \n",
    "    return {\n",
    "        \"total_events\": len(events),\n",
    "        \"event_types\": dict(event_types),\n",
    "        \"thinking_compliance_rate\": thinking[\"compliance_rate\"],\n",
    "        \"temptation_resistance_rate\": temptations[\"resistance_rate\"],\n",
    "        \"temptation_recognition_rate\": temptations[\"recognition_rate\"],\n",
    "        \"most_common_scenario\": max(thinking[\"scenario_counts\"].items(), key=lambda x: x[1])[0] if thinking[\"scenario_counts\"] else \"none\",\n",
    "        \"most_common_temptation\": max(temptations[\"by_type\"].items(), key=lambda x: x[1])[0] if temptations[\"by_type\"] else \"none\",\n",
    "    }\n",
    "\n",
    "if events:\n",
    "    report = generate_summary_report(events)\n",
    "    print(\"=\" * 60)\n",
    "    print(\"COGNITIVE ANALYSIS SUMMARY REPORT\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Total cognitive events: {report['total_events']}\")\n",
    "    print(f\"Event types: {report['event_types']}\")\n",
    "    print(f\"Thinking compliance rate: {report['thinking_compliance_rate']:.1%}\")\n",
    "    print(f\"Temptation recognition rate: {report['temptation_recognition_rate']:.1%}\")\n",
    "    print(f\"Temptation resistance rate: {report['temptation_resistance_rate']:.1%}\")\n",
    "    print(f\"Most common scenario: {report['most_common_scenario']}\")\n",
    "    print(f\"Most common temptation: {report['most_common_temptation']}\")\n",
    "else:\n",
    "    print(\"No events to analyze. Please set TRACE_ID to a valid trace ID.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f665801",
   "metadata": {},
   "source": [
    "## 7. Export Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bfd266",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_report(events: list[CognitiveEvent], output_path: str = \"cognitive_report.json\") -> None:\n",
    "    \"\"\"Export full analysis report to JSON.\"\"\"\n",
    "    report = {\n",
    "        \"generated_at\": datetime.now().isoformat(),\n",
    "        \"trace_id\": TRACE_ID,\n",
    "        \"thinking_analysis\": analyze_thinking_compliance(events),\n",
    "        \"temptation_analysis\": analyze_temptations(events),\n",
    "        \"timeline\": create_timeline(events),\n",
    "        \"reasoning_samples\": get_reasoning_samples(events),\n",
    "    }\n",
    "    \n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump(report, f, indent=2, default=str)\n",
    "    \n",
    "    print(f\"Report exported to {output_path}\")\n",
    "\n",
    "# Uncomment to export:\n",
    "# export_report(events, \"cognitive_report.json\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
