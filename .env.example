# LLM Configuration
# -----------------
# The agent works with any OpenAI-compatible API:
# - vLLM: http://localhost:8000/v1
# - Ollama: http://localhost:11434/v1
# - Venice.ai: https://api.venice.ai/api/v1
# - OpenAI: https://api.openai.com/v1

# Default: Ollama (local)
# export LLM_BASE_URL=http://localhost:11434/v1
# export LLM_API_KEY=ollama
# export LLM_MODEL=llama3.2

# Venice.ai Configuration (recommended for production)
# 
# RECOMMENDED MODELS (235B series):
# - qwen3-235b-a22b-instruct-2507: Best for regular/light work (coding, agents, general tasks)
# - qwen3-235b-a22b-thinking-2507: Best for heavy reasoning (complex analysis, planning)
#
# Other available models:
# - mistral-31-24b: 131k context, vision + function calling ($0.50/$2.00 per 1M tokens)
# - qwen3-coder-480b-a35b-instruct: 262k context, code-focused ($0.75/$3.00 per 1M tokens)
export LLM_BASE_URL=https://api.venice.ai/api/v1
export LLM_API_KEY=your-venice-api-key
export LLM_MODEL=qwen3-235b-a22b-instruct-2507
export LLM_TEMPERATURE=0.7
export LLM_MAX_TOKENS=4096

# Context Configuration
# ---------------------
# These settings control the fundamental context window constraint.
# The token budget is a HARD LIMIT - when exceeded, oldest messages
# are dropped (naive truncation, not summarization).

export CONTEXT_TOKEN_BUDGET=128000
export CONTEXT_CHARS_PER_TOKEN=4.0
export CONTEXT_RESERVED_FOR_RESPONSE=4096

# Agent Loop Configuration
# ------------------------
# max_steps is a safety limit to prevent runaway execution.
# This is an operational constraint that exists in real agent systems.

export AGENT_MAX_STEPS=20

# OCR Configuration (for PDF ingestion)
# --------------------------------------
# OCR uses vision-language models via OpenAI-compatible APIs.
# By default, uses the same LLM_BASE_URL and LLM_API_KEY as the agent.
# Set OCR_* vars to use a different endpoint/model for OCR.

# OCR_BASE_URL=https://api.venice.ai/api/v1  # (defaults to LLM_BASE_URL)
# OCR_MODEL=google-gemma-3-27b-it            # Venice default - good balance
# OCR_PROMPT=                                 # Custom prompt (optional)

# RECOMMENDED OCR MODELS:
#
# Venice.ai (cloud, no GPU needed):
#   OCR_MODEL=google-gemma-3-27b-it          # Best value, good accuracy
#
# vLLM on DGX Spark / local GPU (SOTA accuracy):
#   OCR_BASE_URL=http://localhost:8000/v1
#   OCR_MODEL=allenai/olmOCR-2-7B-1025       # SOTA for documents, 7B params
#   OCR_MODEL=deepseek-ai/DeepSeek-OCR       # Great for tables/charts, 3B params
#   OCR_MODEL=Qwen/Qwen2.5-VL-7B-Instruct    # General vision, 7B params
#
# Note: olmOCR-2 and DeepSeek-OCR are purpose-built for OCR and outperform
# general vision models on document text extraction.
